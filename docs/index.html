<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Interpreting Transformer Hallucinations</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
            background: #0d1117;
            color: #c9d1d9;
        }

        h1 {
            color: #f0f6fc;
            border-bottom: 2px solid #58a6ff;
            padding-bottom: 12px;
            margin-bottom: 10px;
        }

        .subtitle {
            color: #8b949e;
            margin-top: 0;
            font-size: 18px;
        }

        .viz-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 24px;
            margin-top: 40px;
        }

        .viz-card {
            background: #161b22;
            border: 1px solid #30363d;
            border-radius: 10px;
            padding: 24px;
            box-shadow: 0 4px 25px rgba(0, 0, 0, 0.4);
            transition: transform 0.25s ease, box-shadow 0.25s ease;
        }

        .viz-card:hover {
            transform: translateY(-6px);
            box-shadow: 0 8px 35px rgba(0, 0, 0, 0.7);
        }

        .viz-card h3 {
            margin-top: 0;
            color: #58a6ff;
            font-size: 20px;
        }

        .viz-card p {
            color: #8b949e;
            line-height: 1.6;
            font-size: 15px;
        }

        .viz-link {
            display: inline-block;
            margin-top: 15px;
            padding: 9px 18px;
            background: #238636;
            color: #ffffff;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: background 0.2s ease;
        }

        .viz-link:hover {
            background: #2ea043;
        }

        .back-link {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #30363d;
            text-align: center;
        }

        .back-link a {
            color: #58a6ff;
            text-decoration: none;
            font-weight: 500;
        }

        .back-link a:hover {
            text-decoration: underline;
        }

        @media (max-width: 600px) {
            body {
                padding: 30px 15px;
            }
        }
    </style>
</head>

<body>

    <h1>Interpreting Transformer Hallucinations</h1>
    <p class="subtitle">
        Interactive exploration of information flow from input tokens through attention heads to hallucinated outputs in GPT-Neo-125M.
    </p>

    <div class="viz-grid">

        <div class="viz-card">
            <h3>üåä Sankey Flow Diagram</h3>
            <p>
                Traces information flow from structural tokens (".", "who") through attention heads
                (L0_H2 ‚Üí L6_H4 ‚Üí L11_H4) to output token <strong>"United"</strong>.
            </p>
            <p>
                <strong>Insight:</strong> Structural cues, not semantic entity tokens, dominate causal contribution.
            </p>
            <a href="05_sankey_flow.html" class="viz-link">View Sankey ‚Üí</a>
        </div>

        <div class="viz-card">
            <h3>üî• Head Attribution Heatmap</h3>
            <p>
                12√ó12 matrix of attribution scores across all 144 attention heads.
                Reveals sparse computation concentrated in a small subset of heads.
            </p>
            <p>
                <strong>Insight:</strong> Dominant activity localizes to Layers 0, 6, and 11.
            </p>
            <a href="05_head_heatmap.html" class="viz-link">View Heatmap ‚Üí</a>
        </div>

        <div class="viz-card">
            <h3>üï∏Ô∏è 3D Circuit Graph</h3>
            <p>
                Network visualization of top-20 attention heads positioned by
                (layer, head index, attribution score). Interactive 3D rotation.
            </p>
            <p>
                <strong>Insight:</strong> The hallucination propagates through a narrow vertical circuit.
            </p>
            <a href="05_circuit_graph.html" class="viz-link">View 3D Graph ‚Üí</a>
        </div>

    </div>

    <div class="back-link">
        <a href="https://github.com/Shravani018/interpreting-transformer-hallucinations">
            ‚Üê Back to Repository
        </a>
    </div>
</body>
</html>